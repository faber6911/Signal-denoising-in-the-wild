{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to fine-tune our WaveNet using the ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "import copy\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "if colab:\n",
    "  !pip install -q livelossplot\n",
    "  !pip install -q kaldi_io\n",
    "  !pip install -q kaldiio\n",
    "  os.environ['KALDI_ROOT'] = '/content/drive/My Drive/Stage-Imaging/Signal-denoising-in-the-wild'\n",
    "else:\n",
    "    os.environ['KALDI_ROOT'] = '/opt/kaldi/'\n",
    "\n",
    "import kaldi_io\n",
    "import kaldiio\n",
    "#from livelossplot import PlotLosses\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "from pesq import pesq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DWaveNet import DWaveNet\n",
    "from datasets import SequenceDataset\n",
    "from utils import ScheduledOptim, change_path_scp, EnergyConservingLoss, plot_modelPerformance, l1_mse_loss, splitAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 7344 samples with at most 247 samples for one class\n",
      "Totally 816 samples with at most 247 samples for one class\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SequenceDataset('../data/train/trainLAB.scp', '../data/utt2spk.scp', min_length = 16000, colab = False)\n",
    "test_dataset = SequenceDataset('../data/test/testLAB.scp', '../data/utt2spk.scp', min_length = 16000, colab = False)\n",
    "train_data = DataLoader(train_dataset, batch_size = 8, shuffle=True)\n",
    "test_data = DataLoader(test_dataset, batch_size = 8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DWaveNet(in_channels = 1, target_field_length = None, num_layers = 30,\n",
    "                 num_stacks = 3, residual_channels = 128,\n",
    "                 gate_channels = 128, skip_out_channels = 128,\n",
    "                 last_channels=(2048, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  device\n",
    "else:  \n",
    "  os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3, 4'\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pre-trained model from ../log/fine_tuning/wavenet4/model_best.pth.tar\n"
     ]
    }
   ],
   "source": [
    "#optim = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr = 0.001, eps = 1e-08, weight_decay=0.0)\n",
    "optim = ScheduledOptim( # Transformer optimizer\n",
    "        torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad,\n",
    "                   net.parameters()),\n",
    "            betas = (0.9, 0.98),\n",
    "             eps = 1e-09,\n",
    "              weight_decay = 1e-4,\n",
    "               amsgrad = True),\n",
    "                n_warmup_steps = 8000)\n",
    "\n",
    "start_epoch = 1\n",
    "best = {}\n",
    "best['train'] = 100000\n",
    "best['validation'] = 100000\n",
    "best_epoch = -1\n",
    "history = None\n",
    "\n",
    "#pretrain_model_pth = \"../log/denoising/wavenet3/model_best.pth.tar\"\n",
    "pretrain_model_pth = \"../log/fine_tuning/wavenet4/model_best.pth.tar\"\n",
    "\n",
    "# if pretrain_model_pth is not None:\n",
    "#     if os.path.isfile(pretrain_model_pth):\n",
    "#         print('loading pre-trained model from %s' % pretrain_model_pth)\n",
    "#         model_dict = net.state_dict()\n",
    "#         checkpoint = torch.load(pretrain_model_pth, map_location = lambda storage, loc: storage) # load for cpu\n",
    "#         net.load_state_dict({k.replace('module.',''):v for k,v in checkpoint['state_dict'].items()})\n",
    "#     else:\n",
    "#         print(\"===> no checkpoint found at '{}'\".format(pretrain_model_pth))\n",
    "        \n",
    "if pretrain_model_pth is not None:\n",
    "    if os.path.isfile(pretrain_model_pth):\n",
    "        print('loading pre-trained model from %s' % pretrain_model_pth)\n",
    "        model_dict = net.state_dict()\n",
    "        checkpoint = torch.load(pretrain_model_pth, map_location = lambda storage, loc: storage) # load for cpu\n",
    "        \n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_epoch = checkpoint['epoch']\n",
    "        best = checkpoint['best_losses']\n",
    "        history = checkpoint['history']\n",
    "        #print(checkpoint['state_dict'])\n",
    "        #model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        net.load_state_dict({k.replace('module.',''):v for k,v in checkpoint['state_dict'].items()})\n",
    "        \n",
    "        optim.load_state_dict(checkpoint['optimizer'])\n",
    "    else:\n",
    "        print(\"===> no checkpoint found at '{}'\".format(pretrain_model_pth))\n",
    "#         #exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from SpeakerNet import SpeakerNet\n",
    "from DatasetLoader import DatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "if colab:\n",
    "    base_path = '/content/drive/My Drive/Stage-Imaging/'\n",
    "else:\n",
    "    base_path = '/opt/kaldi/egs/'\n",
    "eval = True\n",
    "model = 'ResNetSE34L'\n",
    "trainfunc = 'angleproto'\n",
    "save_path = '/content/drive/My Drive/Stage-Imaging/'\n",
    "max_frames = 300\n",
    "batch_size = 200\n",
    "max_seg_per_spk = 100\n",
    "nDataLoaderThread = 5\n",
    "max_epoch = 500\n",
    "optimizer = 'adam'\n",
    "hard_prob = .5\n",
    "hard_rank = 10\n",
    "margin = 1\n",
    "scale = 15\n",
    "nSpeakers = 5994\n",
    "if colab:\n",
    "    test_path = '/content/drive/My Drive/Datasets/VoxCeleb1_test/wav/'\n",
    "else:\n",
    "    test_path = '/export/corpora/VoxCeleb1_test/wav/'\n",
    "initial_model = 'baseline_lite_ap.model'\n",
    "encoder_type = 'SAP'\n",
    "nOut = 512\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "# defaults\n",
    "lr_decay = .95\n",
    "test_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size is 512, encoder SAP.\n",
      "Initialised AngleProto\n"
     ]
    }
   ],
   "source": [
    "s = SpeakerNet(model = model, trainfunc = trainfunc, max_frames = max_frames, batch_size = batch_size, max_seg_per_spk = max_seg_per_spk, nDataLoaderThread = nDataLoaderThread, encoder_type = encoder_type, nOut = nOut,\n",
    "               test_interval = test_interval, max_epoch = max_epoch, optimizer = optimizer, lr = lr, lr_decay = lr_decay, hard_prob = hard_prob, hard_rank = hard_rank, margin = margin, scale = scale,\n",
    "               nSpeakers = nSpeakers)\n",
    "\n",
    "it = 1\n",
    "prevloss = float(\"inf\")\n",
    "sumloss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model baseline_lite_ap.model loaded!\n"
     ]
    }
   ],
   "source": [
    "## Load model weights\n",
    "modelfiles = glob.glob('%s/model0*.model'%save_path)\n",
    "modelfiles.sort()\n",
    "\n",
    "if len(modelfiles) >= 1:\n",
    "    s.loadParameters(modelfiles[-1]);\n",
    "    print(\"Model %s loaded from previous state!\"%modelfiles[-1]);\n",
    "    it = int(os.path.splitext(os.path.basename(modelfiles[-1]))[0][5:]) + 1\n",
    "elif(initial_model != \"\"):\n",
    "    s.loadParameters(initial_model);\n",
    "    print(\"Model %s loaded!\"%initial_model);\n",
    "\n",
    "for ii in range(0, it-1):\n",
    "    if ii % test_interval == 0:\n",
    "        clr = s.updateLearningRate(lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(start_epoch, best, best_epoch, loaders, model, classifier, optimizer, use_cuda, history = None,\n",
    "                verbose = True, log_dir = '../log/denoising/wavenet5/', save = True):\n",
    "    \n",
    "  idx = np.random.randint(len(test_data.dataset))\n",
    "  clean, dirty, _ = test_dataset[idx]\n",
    "\n",
    "  if use_cuda:\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "  if history is None:\n",
    "    logs = {}\n",
    "    logs['train'] = []\n",
    "    logs['validation'] = []\n",
    "  else:\n",
    "    logs = copy.deepcopy(history)\n",
    "\n",
    "  for epoch in range(start_epoch, start_epoch + 50):  \n",
    "    epoch_losses = {}\n",
    "    \n",
    "    for phase in ['train', 'validation']:\n",
    "      \n",
    "      if phase == 'train':\n",
    "        model.train()\n",
    "        classifier.eval()\n",
    "      else:\n",
    "        model.eval()\n",
    "        classifier.eval()\n",
    "        \n",
    "      if phase == 'train':\n",
    "        print('Epoch %d' % epoch)\n",
    "        start = time.time()\n",
    "      \n",
    "      running_loss = 0.0\n",
    "      \n",
    "      for batch_idx, (target, data, _) in enumerate(tqdm(loaders[phase])):\n",
    "\n",
    "        if use_cuda:\n",
    "          data, target = data.to(device), target.to(device)\n",
    "        denoised = model(data)\n",
    "            \n",
    "        #print(output.size())\n",
    "        #with torch.no_grad():\n",
    "        loss = EnergyConservingLoss(data, denoised, target)\n",
    "        output = F.normalize(classifier.forward(denoised.squeeze(1)), p=2, dim = 1)\n",
    "        target = F.normalize(classifier.forward(target.squeeze(1)), p=2, dim = 1)\n",
    "        loss2 = torch.nn.MSELoss(reduction = 'sum')(output, target)*1000 \n",
    "        #print(loss, loss2)\n",
    "        loss += loss2\n",
    "\n",
    "        if phase == 'train':\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          lr = optimizer.update_learning_rate()\n",
    "          #lr = 0.001\n",
    "        running_loss += loss.detach() #* data.size(0))\n",
    "        #print(running_loss)\n",
    "\n",
    "        del data, target, output, loss, denoised\n",
    "\n",
    "      epoch_loss =  running_loss / len(loaders[phase].dataset)\n",
    "      epoch_losses[phase] = copy.deepcopy(epoch_loss.item())\n",
    "      if phase == 'train':\n",
    "        if verbose:\n",
    "          print('Train Epoch:{}\\tlr:{:.5f}\\tLoss:{:.8f}\\tTime:{:.2f} m'.format(epoch, lr, epoch_loss, (time.time()-start)/60))\n",
    "      else:\n",
    "        if verbose:\n",
    "          print('Validation Loss:{:.8f}'.format(epoch_loss))\n",
    "      logs[phase].extend([epoch_loss.item()])\n",
    "    if save:\n",
    "      if ((epoch_losses['train'] < best['train']) and (epoch_losses['validation'] < best['validation'])):\n",
    "        best = epoch_losses\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_losses': best,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'history': logs\n",
    "        }, log_dir + str(epoch) + \"_\" + str(sum(epoch_losses.values())) + \".h5\")\n",
    "        print(\"===> save to checkpoint at {}\\n\".format(log_dir + 'model_best.pth.tar'))\n",
    "        shutil.copyfile(log_dir + str(epoch) + \"_\" + str(sum(epoch_losses.values())) +\n",
    "                \".h5\", log_dir + 'model_best.pth.tar')\n",
    "        best_epoch = epoch\n",
    "      elif epoch - best_epoch > 5:\n",
    "        print('===> increase delta optimizer')\n",
    "        optimizer.increase_delta()\n",
    "        best_epoch = epoch\n",
    "\n",
    "    plot_modelPerformance(logs, clean, dirty, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {'train' : train_data, 'validation' : test_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd02907bf65e4b26b3c102b07c20ebb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=918.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d5c1da94aae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_model(start_epoch = start_epoch, best = best,\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__S__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             use_cuda = True, verbose = True, history = history, save = True, log_dir = '../log/fine_tuning/wavenet4/')\n",
      "\u001b[0;32m<ipython-input-15-b3744baf2492>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(start_epoch, best, best_epoch, loaders, model, classifier, optimizer, use_cuda, history, verbose, log_dir, save)\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m           \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;31m#lr = 0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/kaldi/egs/Signal-denoising-in-the-wild/SpeakerRecognition/utils.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;34m\"Step by the inner optimizer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kalditorch/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kalditorch/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(start_epoch = start_epoch, best = best,\n",
    "            best_epoch = best_epoch, loaders = loaders,\n",
    "            model = net, classifier = s.__S__, optimizer = optim,\n",
    "            use_cuda = True, verbose = True, history = history, save = True, log_dir = '../log/fine_tuning/wavenet4/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
